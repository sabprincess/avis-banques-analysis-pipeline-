from airflow import DAG



import pendulum
from airflow.operators.python import PythonOperator
from airflow.utils.dates import days_ago
import pendulum
import googlemaps
import psycopg2
import json
from datetime import datetime

# ===== ClÃ© API Google Maps =====
# ====== Fonctions Python ======

def extract_reviews():
    API_KEY = "AIzaSyARCTUfbIUAUUxFbL6z_ZnB30BVLG5anLw"
    """Extrait les avis Google Maps des banques marocaines"""
    gmaps = googlemaps.Client(key=API_KEY)
    avis_extraits = []

    BANQUES = [
        "Attijariwafa Bank", "Banque Centrale Populaire", "BMCE Bank of Africa",
        "BMCI", "CFG Bank", "CIH Bank", "CrÃ©dit Agricole du Maroc", "SociÃ©tÃ© GÃ©nÃ©rale Maroc"
    ]

    for banque in BANQUES:
        places = gmaps.places(query=banque + " Maroc")
        if "results" in places:
            for place in places["results"]:
                place_id = place["place_id"]
                details = gmaps.place(place_id=place_id, fields=["reviews"])
                if "result" in details and "reviews" in details["result"]:
                    for review in details["result"]["reviews"]:
                        avis_extraits.append({
                            "banque_id": place_id,
                            "note": review.get("rating"),
                            "date_review": review.get("time"),
                            "auteur": review.get("author_name"),
                            "commentaire": review.get("text")
                        })

    # ðŸ”¸ Sauvegarder dans le dossier `~/airflow/data/`
    with open("/home/sabrine123/avis.json", "w") as f:
        json.dump(avis_extraits, f, indent=4)

    print(f"âœ… {len(avis_extraits)} avis extraits et sauvegardÃ©s.")


def load_to_postgres():
    """Charge les avis du JSON dans PostgreSQL"""

    with open("/home/sabrine123/avis.json", "r") as f:
        avis = json.load(f)

    if not avis:
        print("âŒ Aucun avis Ã  insÃ©rer.")
        return

    conn = psycopg2.connect(
        dbname="banques_maroc",
        user="postgres",
        host="localhost",
        port="5433"
    )
    cur = conn.cursor()

    for review in avis:
        cur.execute("""
            INSERT INTO avis (banque_id, note, date_review, auteur, commentaire)
            VALUES (%s, %s, TO_TIMESTAMP(%s), %s, %s)
        """, (
            review["banque_id"],
            review["note"],
            review["date_review"],
            review["auteur"],
            review["commentaire"]
        ))

    conn.commit()
    cur.close()
    conn.close()
    print("âœ… Insertion PostgreSQL rÃ©ussie.")


# ====== DÃ©finition du DAG ======
default_args = {
    'owner': 'airflow',
    'retries': 1,
}

with DAG(
    dag_id="dag_google_reviews",
    default_args=default_args,
    schedule='@daily',
    start_date=pendulum.datetime(2025, 1, 1, tz="UTC"),
    catchup=False,
    tags=["banques", "googlemaps", "avis"]
) as dag:

    extract_task = PythonOperator(
        task_id="extract_reviews",
        python_callable=extract_reviews
    )

    load_task = PythonOperator(
        task_id="load_to_postgres",
        python_callable=load_to_postgres
    )

    extract_task >> load_task  # DÃ©pendance


